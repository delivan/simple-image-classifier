{"code":"import * as tslib_1 from \"tslib\";\r\nimport { doc } from '../doc';\r\nimport * as util from '../util';\r\nimport { operation } from './operation';\r\nimport * as ops from './ops';\r\nexport var Reduction;\r\n(function (Reduction) {\r\n    Reduction[Reduction[\"NONE\"] = 0] = \"NONE\";\r\n    Reduction[Reduction[\"MEAN\"] = 1] = \"MEAN\";\r\n    Reduction[Reduction[\"SUM\"] = 2] = \"SUM\";\r\n    Reduction[Reduction[\"SUM_BY_NONZERO_WEIGHTS\"] = 3] = \"SUM_BY_NONZERO_WEIGHTS\";\r\n})(Reduction || (Reduction = {}));\r\nvar LossOps = (function () {\r\n    function LossOps() {\r\n    }\r\n    LossOps.computeWeightedLoss = function (losses, weights, reduction) {\r\n        if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\r\n        util.assertArgumentsAreTensors({ losses: losses }, 'computeWeightedLoss');\r\n        if (weights != null) {\r\n            util.assertArgumentsAreTensors({ weights: weights }, 'computeWeightedLoss');\r\n        }\r\n        var weightedLoss = (weights == null) ? losses : losses.mul(weights);\r\n        if (reduction === Reduction.NONE) {\r\n            return weightedLoss;\r\n        }\r\n        if (reduction === Reduction.SUM) {\r\n            return weightedLoss.sum();\r\n        }\r\n        if (reduction === Reduction.MEAN) {\r\n            return (weights == null) ? weightedLoss.mean() :\r\n                weightedLoss.sum().div(weights.sum());\r\n        }\r\n        if (reduction === Reduction.SUM_BY_NONZERO_WEIGHTS) {\r\n            if (weights == null) {\r\n                return weightedLoss.sum().div(ops.scalar(losses.size));\r\n            }\r\n            else {\r\n                var numNonZeros = weights.notEqual(ops.scalar(0)).sum().toFloat();\r\n                return weightedLoss.sum().div(numNonZeros);\r\n            }\r\n        }\r\n        throw Error(\"Unknown reduction: \" + reduction);\r\n    };\r\n    LossOps.absoluteDifference = function (labels, predictions, weights, reduction) {\r\n        if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\r\n        util.assertArgumentsAreTensors({ labels: labels, predictions: predictions }, 'absoluteDifference');\r\n        if (weights != null) {\r\n            util.assertArgumentsAreTensors({ weights: weights }, 'absoluteDifference');\r\n        }\r\n        util.assertShapesMatch(labels.shape, predictions.shape, 'Error in absoluteDifference: ');\r\n        var losses = labels.sub(predictions).abs();\r\n        return LossOps.computeWeightedLoss(losses, weights, reduction);\r\n    };\r\n    LossOps.meanSquaredError = function (labels, predictions, weights, reduction) {\r\n        if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\r\n        util.assertArgumentsAreTensors({ labels: labels, predictions: predictions }, 'meanSquaredError');\r\n        if (weights != null) {\r\n            util.assertArgumentsAreTensors({ weights: weights }, 'meanSquaredError');\r\n        }\r\n        util.assertShapesMatch(labels.shape, predictions.shape, 'Error in meanSquaredError: ');\r\n        var losses = labels.squaredDifference(predictions);\r\n        return LossOps.computeWeightedLoss(losses, weights, reduction);\r\n    };\r\n    LossOps.cosineDistance = function (labels, predictions, axis, weights, reduction) {\r\n        if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\r\n        util.assertArgumentsAreTensors({ labels: labels, predictions: predictions }, 'cosineDistance');\r\n        if (weights != null) {\r\n            util.assertArgumentsAreTensors({ weights: weights }, 'cosineDistance');\r\n        }\r\n        util.assertShapesMatch(labels.shape, predictions.shape, 'Error in cosineDistance: ');\r\n        var one = ops.scalar(1);\r\n        var losses = one.sub(labels.mul(predictions).sum(axis, true));\r\n        return LossOps.computeWeightedLoss(losses, weights, reduction);\r\n    };\r\n    LossOps.hingeLoss = function (labels, predictions, weights, reduction) {\r\n        if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\r\n        util.assertArgumentsAreTensors({ labels: labels, predictions: predictions }, 'hingeLoss');\r\n        if (weights != null) {\r\n            util.assertArgumentsAreTensors({ weights: weights }, 'hingeLoss');\r\n        }\r\n        util.assertShapesMatch(labels.shape, predictions.shape, 'Error in hingeLoss: ');\r\n        var one = ops.scalar(1);\r\n        labels = ops.scalar(2).mul(labels).sub(one);\r\n        var losses = one.sub(labels.mul(predictions)).relu();\r\n        return LossOps.computeWeightedLoss(losses, weights, reduction);\r\n    };\r\n    LossOps.logLoss = function (labels, predictions, weights, epsilon, reduction) {\r\n        if (epsilon === void 0) { epsilon = 1e-7; }\r\n        if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\r\n        util.assertArgumentsAreTensors({ labels: labels, predictions: predictions }, 'logLoss');\r\n        if (weights != null) {\r\n            util.assertArgumentsAreTensors({ weights: weights }, 'logLoss');\r\n        }\r\n        util.assertShapesMatch(labels.shape, predictions.shape, 'Error in logLoss: ');\r\n        var one = ops.scalar(1);\r\n        var epsilonScalar = ops.scalar(epsilon);\r\n        var losses = labels.mul(predictions.add(epsilonScalar).log())\r\n            .neg()\r\n            .sub(one.sub(labels).mul(one.sub(predictions).add(epsilonScalar).log()));\r\n        return LossOps.computeWeightedLoss(losses, weights, reduction);\r\n    };\r\n    tslib_1.__decorate([\r\n        doc({ heading: 'Training', subheading: 'Losses', namespace: 'losses' }),\r\n        operation\r\n    ], LossOps, \"computeWeightedLoss\", null);\r\n    tslib_1.__decorate([\r\n        doc({ heading: 'Training', subheading: 'Losses', namespace: 'losses' }),\r\n        operation\r\n    ], LossOps, \"absoluteDifference\", null);\r\n    tslib_1.__decorate([\r\n        doc({ heading: 'Training', subheading: 'Losses', namespace: 'losses' }),\r\n        operation\r\n    ], LossOps, \"meanSquaredError\", null);\r\n    tslib_1.__decorate([\r\n        doc({ heading: 'Training', subheading: 'Losses', namespace: 'losses' }),\r\n        operation\r\n    ], LossOps, \"cosineDistance\", null);\r\n    tslib_1.__decorate([\r\n        doc({ heading: 'Training', subheading: 'Losses', namespace: 'losses' }),\r\n        operation\r\n    ], LossOps, \"hingeLoss\", null);\r\n    tslib_1.__decorate([\r\n        doc({ heading: 'Training', subheading: 'Losses', namespace: 'losses' }),\r\n        operation\r\n    ], LossOps, \"logLoss\", null);\r\n    return LossOps;\r\n}());\r\nexport { LossOps };\r\n//# sourceMappingURL=loss_ops.js.map","map":"{\"version\":3,\"file\":\"loss_ops.js\",\"sourceRoot\":\"\",\"sources\":[\"../src/ops/loss_ops.ts\"],\"names\":[],\"mappings\":\";AAiBA,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAE3B,OAAO,KAAK,IAAI,MAAM,SAAS,CAAC;AAEhC,OAAO,EAAC,SAAS,EAAC,MAAM,aAAa,CAAC;AACtC,OAAO,KAAK,GAAG,MAAM,OAAO,CAAC;AAE7B,MAAM,CAAN,IAAY,SAKX;AALD,WAAY,SAAS;IACnB,yCAAI,CAAA;IACJ,yCAAI,CAAA;IACJ,uCAAG,CAAA;IACH,6EAAsB,CAAA;AACxB,CAAC,EALW,SAAS,KAAT,SAAS,QAKpB;AAED;IAAA;IAuMA,CAAC;IA3LQ,2BAAmB,GAA1B,UACI,MAAS,EAAE,OAAgB,EAC3B,SAA4C;QAA5C,0BAAA,EAAA,YAAY,SAAS,CAAC,sBAAsB;QAC9C,IAAI,CAAC,yBAAyB,CAAC,EAAC,MAAM,QAAA,EAAC,EAAE,qBAAqB,CAAC,CAAC;QAChE,EAAE,CAAC,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC;YACpB,IAAI,CAAC,yBAAyB,CAAC,EAAC,OAAO,SAAA,EAAC,EAAE,qBAAqB,CAAC,CAAC;QACnE,CAAC;QAED,IAAM,YAAY,GAAG,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC;QAEtE,EAAE,CAAC,CAAC,SAAS,KAAK,SAAS,CAAC,IAAI,CAAC,CAAC,CAAC;YACjC,MAAM,CAAC,YAAiB,CAAC;QAC3B,CAAC;QACD,EAAE,CAAC,CAAC,SAAS,KAAK,SAAS,CAAC,GAAG,CAAC,CAAC,CAAC;YAChC,MAAM,CAAC,YAAY,CAAC,GAAG,EAAE,CAAC;QAC5B,CAAC;QACD,EAAE,CAAC,CAAC,SAAS,KAAK,SAAS,CAAC,IAAI,CAAC,CAAC,CAAC;YACjC,MAAM,CAAC,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,YAAY,CAAC,IAAI,EAAE,CAAC,CAAC;gBACrB,YAAY,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,OAAO,CAAC,GAAG,EAAE,CAAC,CAAC;QACnE,CAAC;QACD,EAAE,CAAC,CAAC,SAAS,KAAK,SAAS,CAAC,sBAAsB,CAAC,CAAC,CAAC;YACnD,EAAE,CAAC,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC;gBACpB,MAAM,CAAC,YAAY,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC;YACzD,CAAC;YAAC,IAAI,CAAC,CAAC;gBACN,IAAM,WAAW,GAAG,OAAO,CAAC,QAAQ,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,EAAE,CAAC,OAAO,EAAE,CAAC;gBACpE,MAAM,CAAC,YAAY,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,WAAW,CAAC,CAAC;YAC7C,CAAC;QACH,CAAC;QAED,MAAM,KAAK,CAAC,wBAAsB,SAAW,CAAC,CAAC;IACjD,CAAC;IAiBM,0BAAkB,GAAzB,UACI,MAAS,EAAE,WAAc,EAAE,OAAgB,EAC3C,SAA4C;QAA5C,0BAAA,EAAA,YAAY,SAAS,CAAC,sBAAsB;QAC9C,IAAI,CAAC,yBAAyB,CAAC,EAAC,MAAM,QAAA,EAAE,WAAW,aAAA,EAAC,EAAE,oBAAoB,CAAC,CAAC;QAC5E,EAAE,CAAC,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC;YACpB,IAAI,CAAC,yBAAyB,CAAC,EAAC,OAAO,SAAA,EAAC,EAAE,oBAAoB,CAAC,CAAC;QAClE,CAAC;QACD,IAAI,CAAC,iBAAiB,CAClB,MAAM,CAAC,KAAK,EAAE,WAAW,CAAC,KAAK,EAAE,+BAA+B,CAAC,CAAC;QAEtE,IAAM,MAAM,GAAG,MAAM,CAAC,GAAG,CAAC,WAAW,CAAC,CAAC,GAAG,EAAE,CAAC;QAC7C,MAAM,CAAC,OAAO,CAAC,mBAAmB,CAAC,MAAM,EAAE,OAAO,EAAE,SAAS,CAAC,CAAC;IACjE,CAAC;IAiBM,wBAAgB,GAAvB,UACI,MAAS,EAAE,WAAc,EAAE,OAAgB,EAC3C,SAA4C;QAA5C,0BAAA,EAAA,YAAY,SAAS,CAAC,sBAAsB;QAC9C,IAAI,CAAC,yBAAyB,CAAC,EAAC,MAAM,QAAA,EAAE,WAAW,aAAA,EAAC,EAAE,kBAAkB,CAAC,CAAC;QAC1E,EAAE,CAAC,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC;YACpB,IAAI,CAAC,yBAAyB,CAAC,EAAC,OAAO,SAAA,EAAC,EAAE,kBAAkB,CAAC,CAAC;QAChE,CAAC;QACD,IAAI,CAAC,iBAAiB,CAClB,MAAM,CAAC,KAAK,EAAE,WAAW,CAAC,KAAK,EAAE,6BAA6B,CAAC,CAAC;QAEpE,IAAM,MAAM,GAAG,MAAM,CAAC,iBAAiB,CAAC,WAAW,CAAC,CAAC;QACrD,MAAM,CAAC,OAAO,CAAC,mBAAmB,CAAC,MAAM,EAAE,OAAO,EAAE,SAAS,CAAC,CAAC;IACjE,CAAC;IAkBM,sBAAc,GAArB,UACI,MAAS,EAAE,WAAc,EAAE,IAAY,EAAE,OAAgB,EACzD,SAA4C;QAA5C,0BAAA,EAAA,YAAY,SAAS,CAAC,sBAAsB;QAC9C,IAAI,CAAC,yBAAyB,CAAC,EAAC,MAAM,QAAA,EAAE,WAAW,aAAA,EAAC,EAAE,gBAAgB,CAAC,CAAC;QACxE,EAAE,CAAC,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC;YACpB,IAAI,CAAC,yBAAyB,CAAC,EAAC,OAAO,SAAA,EAAC,EAAE,gBAAgB,CAAC,CAAC;QAC9D,CAAC;QACD,IAAI,CAAC,iBAAiB,CAClB,MAAM,CAAC,KAAK,EAAE,WAAW,CAAC,KAAK,EAAE,2BAA2B,CAAC,CAAC;QAElE,IAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC;QAC1B,IAAM,MAAM,GAAG,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,WAAW,CAAC,CAAC,GAAG,CAAC,IAAI,EAAE,IAAI,CAAC,CAAC,CAAC;QAChE,MAAM,CAAC,OAAO,CAAC,mBAAmB,CAAC,MAAM,EAAE,OAAO,EAAE,SAAS,CAAC,CAAC;IACjE,CAAC;IAiBM,iBAAS,GAAhB,UACI,MAAS,EAAE,WAAc,EAAE,OAAgB,EAC3C,SAA4C;QAA5C,0BAAA,EAAA,YAAY,SAAS,CAAC,sBAAsB;QAC9C,IAAI,CAAC,yBAAyB,CAAC,EAAC,MAAM,QAAA,EAAE,WAAW,aAAA,EAAC,EAAE,WAAW,CAAC,CAAC;QACnE,EAAE,CAAC,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC;YACpB,IAAI,CAAC,yBAAyB,CAAC,EAAC,OAAO,SAAA,EAAC,EAAE,WAAW,CAAC,CAAC;QACzD,CAAC;QACD,IAAI,CAAC,iBAAiB,CAClB,MAAM,CAAC,KAAK,EAAE,WAAW,CAAC,KAAK,EAAE,sBAAsB,CAAC,CAAC;QAE7D,IAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC;QAE1B,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;QAC5C,IAAM,MAAM,GAAG,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,WAAW,CAAC,CAAC,CAAC,IAAI,EAAE,CAAC;QACvD,MAAM,CAAC,OAAO,CAAC,mBAAmB,CAAC,MAAM,EAAE,OAAO,EAAE,SAAS,CAAC,CAAC;IACjE,CAAC;IAkBM,eAAO,GAAd,UACI,MAAS,EAAE,WAAc,EAAE,OAAgB,EAAE,OAAc,EAC3D,SAA4C;QADC,wBAAA,EAAA,cAAc;QAC3D,0BAAA,EAAA,YAAY,SAAS,CAAC,sBAAsB;QAC9C,IAAI,CAAC,yBAAyB,CAAC,EAAC,MAAM,QAAA,EAAE,WAAW,aAAA,EAAC,EAAE,SAAS,CAAC,CAAC;QACjE,EAAE,CAAC,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC;YACpB,IAAI,CAAC,yBAAyB,CAAC,EAAC,OAAO,SAAA,EAAC,EAAE,SAAS,CAAC,CAAC;QACvD,CAAC;QACD,IAAI,CAAC,iBAAiB,CAClB,MAAM,CAAC,KAAK,EAAE,WAAW,CAAC,KAAK,EAAE,oBAAoB,CAAC,CAAC;QAE3D,IAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC;QAC1B,IAAM,aAAa,GAAG,GAAG,CAAC,MAAM,CAAC,OAAO,CAAC,CAAC;QAC1C,IAAM,MAAM,GAAG,MAAM,CAAC,GAAG,CAAC,WAAW,CAAC,GAAG,CAAC,aAAa,CAAC,CAAC,GAAG,EAAE,CAAC;aAC3C,GAAG,EAAE;aACL,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,GAAG,CACpB,GAAG,CAAC,GAAG,CAAC,WAAW,CAAC,CAAC,GAAG,CAAC,aAAa,CAAC,CAAC,GAAG,EAAE,CAAC,CAAC,CAAC;QACvE,MAAM,CAAC,OAAO,CAAC,mBAAmB,CAAC,MAAM,EAAE,OAAO,EAAE,SAAS,CAAC,CAAC;IACjE,CAAC;IA1LD;QAFC,GAAG,CAAC,EAAC,OAAO,EAAE,UAAU,EAAE,UAAU,EAAE,QAAQ,EAAE,SAAS,EAAE,QAAQ,EAAC,CAAC;QACrE,SAAS;4CA+BT;IAiBD;QAFC,GAAG,CAAC,EAAC,OAAO,EAAE,UAAU,EAAE,UAAU,EAAE,QAAQ,EAAE,SAAS,EAAE,QAAQ,EAAC,CAAC;QACrE,SAAS;2CAaT;IAiBD;QAFC,GAAG,CAAC,EAAC,OAAO,EAAE,UAAU,EAAE,UAAU,EAAE,QAAQ,EAAE,SAAS,EAAE,QAAQ,EAAC,CAAC;QACrE,SAAS;yCAaT;IAkBD;QAFC,GAAG,CAAC,EAAC,OAAO,EAAE,UAAU,EAAE,UAAU,EAAE,QAAQ,EAAE,SAAS,EAAE,QAAQ,EAAC,CAAC;QACrE,SAAS;uCAcT;IAiBD;QAFC,GAAG,CAAC,EAAC,OAAO,EAAE,UAAU,EAAE,UAAU,EAAE,QAAQ,EAAE,SAAS,EAAE,QAAQ,EAAC,CAAC;QACrE,SAAS;kCAgBT;IAkBD;QAFC,GAAG,CAAC,EAAC,OAAO,EAAE,UAAU,EAAE,UAAU,EAAE,QAAQ,EAAE,SAAS,EAAE,QAAQ,EAAC,CAAC;QACrE,SAAS;gCAkBT;IACH,cAAC;CAAA,AAvMD,IAuMC;SAvMY,OAAO\"}","dts":{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/rollup/tfjs-core/ops/loss_ops.d.ts","text":"import { Tensor } from '../tensor';\r\nexport declare enum Reduction {\r\n    NONE = 0,\r\n    MEAN = 1,\r\n    SUM = 2,\r\n    SUM_BY_NONZERO_WEIGHTS = 3,\r\n}\r\nexport declare class LossOps {\r\n    static computeWeightedLoss<T extends Tensor, O extends Tensor>(losses: T, weights?: Tensor, reduction?: Reduction): O;\r\n    static absoluteDifference<T extends Tensor, O extends Tensor>(labels: T, predictions: T, weights?: Tensor, reduction?: Reduction): O;\r\n    static meanSquaredError<T extends Tensor, O extends Tensor>(labels: T, predictions: T, weights?: Tensor, reduction?: Reduction): O;\r\n    static cosineDistance<T extends Tensor, O extends Tensor>(labels: T, predictions: T, axis: number, weights?: Tensor, reduction?: Reduction): O;\r\n    static hingeLoss<T extends Tensor, O extends Tensor>(labels: T, predictions: T, weights?: Tensor, reduction?: Reduction): O;\r\n    static logLoss<T extends Tensor, O extends Tensor>(labels: T, predictions: T, weights?: Tensor, epsilon?: number, reduction?: Reduction): O;\r\n}\r\n"}}
