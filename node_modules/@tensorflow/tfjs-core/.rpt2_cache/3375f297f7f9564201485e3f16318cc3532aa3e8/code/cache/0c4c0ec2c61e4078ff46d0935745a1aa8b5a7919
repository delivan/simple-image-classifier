{"code":"import * as tslib_1 from \"tslib\";\r\nimport { doc } from '../doc';\r\nimport { customGrad } from '../globals';\r\nimport * as util from '../util';\r\nimport * as axis_util from './axis_util';\r\nimport { operation } from './operation';\r\nimport * as ops from './ops';\r\nvar SoftmaxOps = (function () {\r\n    function SoftmaxOps() {\r\n    }\r\n    SoftmaxOps.softmax = function (logits, dim) {\r\n        if (dim === void 0) { dim = -1; }\r\n        util.assertArgumentsAreTensors({ logits: logits }, 'softmax');\r\n        if (dim === -1) {\r\n            dim = logits.rank - 1;\r\n        }\r\n        if (dim !== logits.rank - 1) {\r\n            throw Error('Softmax along a non-last dimension is not yet supported. ' +\r\n                (\"Logits was rank \" + logits.rank + \" and dim was \" + dim));\r\n        }\r\n        var customOp = customGrad(function (logits) {\r\n            var keepDims = true;\r\n            var lse = logits.logSumExp([dim], keepDims);\r\n            var logResult = logits.toFloat().sub(lse);\r\n            var y = logResult.exp();\r\n            var gradFunc = function (dy) {\r\n                var dyTimesY = dy.mul(y);\r\n                var keepDims = true;\r\n                return dyTimesY.sub(dyTimesY.sum([dim], keepDims).mul(y));\r\n            };\r\n            return { value: y, gradFunc: gradFunc };\r\n        });\r\n        return customOp(logits);\r\n    };\r\n    SoftmaxOps.softmaxCrossEntropy = function (labels, logits, dim) {\r\n        if (dim === void 0) { dim = -1; }\r\n        util.assertArgumentsAreTensors({ labels: labels, logits: logits }, 'softmaxCrossEntropy');\r\n        util.assertShapesMatch(labels.shape, logits.shape, 'Error in softmaxCrossEntropy: ');\r\n        if (dim === -1) {\r\n            dim = logits.rank - 1;\r\n        }\r\n        if (dim !== logits.rank - 1) {\r\n            throw Error(\"Softmax cross entropy along a non-last dimension is not yet \" +\r\n                (\"supported. Labels / logits was rank \" + logits.rank + \" \") +\r\n                (\"and dim was \" + dim));\r\n        }\r\n        var customOp = customGrad(function (labels, logits) {\r\n            var predictedProbs = logits.softmax(dim);\r\n            var costVector = ops.scalar(1e-5).add(predictedProbs).log().mul(labels).neg();\r\n            var value = costVector.sum([dim]);\r\n            var gradFunc = function (dy) {\r\n                var dyShape = axis_util.expandShapeToKeepDim(dy.shape, [dim]);\r\n                return [\r\n                    dy.reshape(dyShape).mul(labels.toFloat().sub(predictedProbs)),\r\n                    dy.reshape(dyShape).mul(predictedProbs.sub(labels.toFloat())),\r\n                ];\r\n            };\r\n            return { value: value, gradFunc: gradFunc };\r\n        });\r\n        return customOp(labels, logits);\r\n    };\r\n    tslib_1.__decorate([\r\n        doc({ heading: 'Operations', subheading: 'Normalization' }),\r\n        operation\r\n    ], SoftmaxOps, \"softmax\", null);\r\n    tslib_1.__decorate([\r\n        doc({ heading: 'Training', subheading: 'Losses', namespace: 'losses' }),\r\n        operation\r\n    ], SoftmaxOps, \"softmaxCrossEntropy\", null);\r\n    return SoftmaxOps;\r\n}());\r\nexport { SoftmaxOps };\r\n//# sourceMappingURL=softmax.js.map","map":"{\"version\":3,\"file\":\"softmax.js\",\"sourceRoot\":\"\",\"sources\":[\"../src/ops/softmax.ts\"],\"names\":[],\"mappings\":\";AAiBA,OAAO,EAAC,GAAG,EAAC,MAAM,QAAQ,CAAC;AAC3B,OAAO,EAAC,UAAU,EAAC,MAAM,YAAY,CAAC;AAEtC,OAAO,KAAK,IAAI,MAAM,SAAS,CAAC;AAEhC,OAAO,KAAK,SAAS,MAAM,aAAa,CAAC;AACzC,OAAO,EAAC,SAAS,EAAC,MAAM,aAAa,CAAC;AACtC,OAAO,KAAK,GAAG,MAAM,OAAO,CAAC;AAE7B;IAAA;IAkHA,CAAC;IA5FQ,kBAAO,GAAd,UAAiC,MAAS,EAAE,GAAQ;QAAR,oBAAA,EAAA,OAAO,CAAC;QAClD,IAAI,CAAC,yBAAyB,CAAC,EAAC,MAAM,QAAA,EAAC,EAAE,SAAS,CAAC,CAAC;QAEpD,EAAE,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;YACf,GAAG,GAAG,MAAM,CAAC,IAAI,GAAG,CAAC,CAAC;QACxB,CAAC;QACD,EAAE,CAAC,CAAC,GAAG,KAAK,MAAM,CAAC,IAAI,GAAG,CAAC,CAAC,CAAC,CAAC;YAC5B,MAAM,KAAK,CACP,2DAA2D;iBAC3D,qBAAmB,MAAM,CAAC,IAAI,qBAAgB,GAAK,CAAA,CAAC,CAAC;QAC3D,CAAC;QAED,IAAM,QAAQ,GAAG,UAAU,CAAC,UAAA,MAAM;YAGhC,IAAM,QAAQ,GAAG,IAAI,CAAC;YACtB,IAAM,GAAG,GAAG,MAAM,CAAC,SAAS,CAAC,CAAC,GAAG,CAAC,EAAE,QAAQ,CAAC,CAAC;YAC9C,IAAM,SAAS,GAAG,MAAM,CAAC,OAAO,EAAE,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;YAC5C,IAAM,CAAC,GAAG,SAAS,CAAC,GAAG,EAAO,CAAC;YAE/B,IAAM,QAAQ,GAAG,UAAC,EAAK;gBACrB,IAAM,QAAQ,GAAG,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;gBAC3B,IAAM,QAAQ,GAAG,IAAI,CAAC;gBACtB,MAAM,CAAC,QAAQ,CAAC,GAAG,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,EAAE,QAAQ,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC;YAC5D,CAAC,CAAC;YAEF,MAAM,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,QAAQ,UAAA,EAAC,CAAC;QAC9B,CAAC,CAAC,CAAC;QAEH,MAAM,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC;IAC1B,CAAC;IA4BM,8BAAmB,GAA1B,UACI,MAAS,EAAE,MAAS,EAAE,GAAQ;QAAR,oBAAA,EAAA,OAAO,CAAC;QAChC,IAAI,CAAC,yBAAyB,CAAC,EAAC,MAAM,QAAA,EAAE,MAAM,QAAA,EAAC,EAAE,qBAAqB,CAAC,CAAC;QACxE,IAAI,CAAC,iBAAiB,CAClB,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,KAAK,EAAE,gCAAgC,CAAC,CAAC;QAElE,EAAE,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;YACf,GAAG,GAAG,MAAM,CAAC,IAAI,GAAG,CAAC,CAAC;QACxB,CAAC;QACD,EAAE,CAAC,CAAC,GAAG,KAAK,MAAM,CAAC,IAAI,GAAG,CAAC,CAAC,CAAC,CAAC;YAC5B,MAAM,KAAK,CACP,8DAA8D;iBAC9D,yCAAuC,MAAM,CAAC,IAAI,MAAG,CAAA;iBACrD,iBAAe,GAAK,CAAA,CAAC,CAAC;QAC5B,CAAC;QAED,IAAM,QAAQ,GAAG,UAAU,CAAC,UAAC,MAAM,EAAE,MAAM;YACzC,IAAM,cAAc,GAAG,MAAM,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC;YAC3C,IAAM,UAAU,GACZ,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,cAAc,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,GAAG,EAAE,CAAC;YACjE,IAAM,KAAK,GAAG,UAAU,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAM,CAAC;YAEzC,IAAM,QAAQ,GAAG,UAAC,EAAK;gBACrB,IAAM,OAAO,GAAG,SAAS,CAAC,oBAAoB,CAAC,EAAE,CAAC,KAAK,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC;gBAChE,MAAM,CAAC;oBACL,EAAE,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,GAAG,CAAC,MAAM,CAAC,OAAO,EAAE,CAAC,GAAG,CAAC,cAAc,CAAC,CAAC;oBAC7D,EAAE,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,GAAG,CAAC,cAAc,CAAC,GAAG,CAAC,MAAM,CAAC,OAAO,EAAE,CAAC,CAAC;iBAC9D,CAAC;YACJ,CAAC,CAAC;YACF,MAAM,CAAC,EAAC,KAAK,OAAA,EAAE,QAAQ,UAAA,EAAC,CAAC;QAC3B,CAAC,CAAC,CAAC;QAEH,MAAM,CAAC,QAAQ,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;IAClC,CAAC;IA3FD;QAFC,GAAG,CAAC,EAAC,OAAO,EAAE,YAAY,EAAE,UAAU,EAAE,eAAe,EAAC,CAAC;QACzD,SAAS;mCA+BT;IA4BD;QAFC,GAAG,CAAC,EAAC,OAAO,EAAE,UAAU,EAAE,UAAU,EAAE,QAAQ,EAAE,SAAS,EAAE,QAAQ,EAAC,CAAC;QACrE,SAAS;+CAkCT;IACH,iBAAC;CAAA,AAlHD,IAkHC;SAlHY,UAAU\"}","dts":{"name":"/usr/local/google/home/nsthorat/deeplearnjs-clients/rollup/tfjs-core/ops/softmax.d.ts","text":"import { Tensor } from '../tensor';\r\nexport declare class SoftmaxOps {\r\n    static softmax<T extends Tensor>(logits: T, dim?: number): T;\r\n    static softmaxCrossEntropy<T extends Tensor, O extends Tensor>(labels: T, logits: T, dim?: number): O;\r\n}\r\n"}}
